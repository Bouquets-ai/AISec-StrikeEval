import json
import os
import sys
import time
import random
import argparse
import html
import re
import threading
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib import request, error


def load_questions(path):
    with open(path, 'r', encoding='utf-8-sig') as f:
        data = json.load(f)
    questions = []
    for q in data:
        idv = q.get('id') or q.get('question_id')
        question = q.get('question')
        options = q.get('options')
        answer = q.get('answer')
        if idv is None or question is None or options is None or answer is None:
            continue
        questions.append({
            'id': str(idv),
            'question': question,
            'options': options,
            'answer': answer,
        })
    return questions

def analyze_questions_file(path):
    with open(path, 'r', encoding='utf-8-sig') as f:
        data = json.load(f)
    valid = []
    invalid = []
    for q in data:
        idv = q.get('id') or q.get('question_id')
        question = q.get('question')
        options = q.get('options')
        answer = q.get('answer')
        if idv is None or question is None or options is None or answer is None:
            invalid.append({
                'id': idv,
                'has_question': question is not None,
                'has_options': options is not None,
                'has_answer': answer is not None,
            })
        else:
            valid.append({
                'id': str(idv),
                'question': question,
                'options': options,
                'answer': answer,
            })
    return valid, invalid

def load_questions_freeform(path):
    with open(path, 'r', encoding='utf-8-sig') as f:
        data = json.load(f)
    questions = []
    for q in data:
        if 'id' in q and ('question' in q or 'prompt' in q):
            nq = {
                'id': q['id'],
                'question': q.get('question') or q.get('prompt') or '',
                'options': q.get('options') or {}
            }
            if nq['question']:
                questions.append(nq)
    return questions


def build_prompt(q):
    instruction = (
        "è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦è§£é‡Šã€‚\n"
        "è‹¥ä¸ºé€‰æ‹©é¢˜ï¼ˆå‡ºç°A-Dé€‰é¡¹æˆ–é¢˜å¹²å«â€˜å•é€‰é¢˜/å¤šé€‰é¢˜â€™ï¼‰ï¼Œä»…è¾“å‡ºå­—æ¯ï¼›\n"
        "è‹¥ä¸ºåˆ¤æ–­é¢˜ï¼Œä»…è¾“å‡ºâ€˜å¯¹â€™æˆ–â€˜é”™â€™ï¼›\n"
        "æœ€åä¸€è¡Œä½¿ç”¨ â€˜Final Answer: <ç­”æ¡ˆ>â€™ æ ‡æ³¨æœ€ç»ˆç­”æ¡ˆã€‚\n"
    )
    options = q.get('options', {})
    opt_lines = [
        f"A. {options.get('A', '')}",
        f"B. {options.get('B', '')}",
        f"C. {options.get('C', '')}",
        f"D. {options.get('D', '')}",
    ]
    prompt = f"{instruction}\né¢˜ç›®ï¼š{q.get('question','')}\né€‰é¡¹ï¼š\n" + "\n".join(opt_lines) + "\nä½ çš„ç­”æ¡ˆï¼š"
    return prompt

def build_prompt_freeform(q):
    instruction_selective = (
        "è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦è§£é‡Šã€‚\n"
        "è‹¥ä¸ºé€‰æ‹©é¢˜ï¼ˆå‡ºç°A-Dé€‰é¡¹æˆ–é¢˜å¹²å«â€˜å•é€‰é¢˜/å¤šé€‰é¢˜â€™ï¼‰ï¼Œä»…è¾“å‡ºå­—æ¯ï¼›è‹¥ä¸ºå¤šé€‰é¢˜ï¼Œè¾“å‡ºæ‰€æœ‰ç¬¦åˆçš„é€‰é¡¹å­—æ¯ï¼Œå¹¶ç”¨é€—å·åˆ†éš”ï¼ˆä¾‹å¦‚ A,B,Dï¼‰ï¼›\n"
        "è‹¥ä¸ºåˆ¤æ–­é¢˜ï¼Œä»…è¾“å‡ºâ€˜å¯¹â€™æˆ–â€˜é”™â€™ï¼›\n"
        "æœ€åä¸€è¡Œä½¿ç”¨ â€˜Final Answer: <ç­”æ¡ˆ>â€™ æ ‡æ³¨æœ€ç»ˆç­”æ¡ˆã€‚\n"
    )
    instruction_generic = (
        "è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦è§£é‡Šã€‚\n"
        "è‹¥ä¸ºåˆ¤æ–­é¢˜ï¼Œä»…è¾“å‡ºâ€˜å¯¹â€™æˆ–â€˜é”™â€™ï¼›\n"
        "å…¶å®ƒé¢˜å‹è¯·è¾“å‡ºç®€æ´æ–‡æœ¬ç­”æ¡ˆã€‚\n"
        "æœ€åä¸€è¡Œä½¿ç”¨ â€˜Final Answer: <ç­”æ¡ˆ>â€™ æ ‡æ³¨æœ€ç»ˆç­”æ¡ˆã€‚\n"
    )
    options = q.get('options', {})
    opt_lines = []
    if options:
        opt_lines = [
            f"A. {options.get('A', '')}",
            f"B. {options.get('B', '')}",
            f"C. {options.get('C', '')}",
            f"D. {options.get('D', '')}",
        ]
    opt_block = ("\né€‰é¡¹ï¼š\n" + "\n".join(opt_lines)) if opt_lines else ""
    qtext = q.get('question') or q.get('prompt') or ''
    lt = str(qtext).lower()
    detected = None
    if ("å¤šé€‰é¢˜" in str(qtext)) or ("multiple-choice" in lt) or ("multiple choice" in lt):
        detected = "å¤šé€‰é¢˜"
    elif ("å•é€‰é¢˜" in str(qtext)) or ("single-choice" in lt) or ("single choice" in lt):
        detected = "å•é€‰é¢˜"
    elif ("åˆ¤æ–­é¢˜" in str(qtext)) or ("true/false" in lt) or ("true or false" in lt) or ("åˆ¤æ–­" in str(qtext)):
        detected = "åˆ¤æ–­é¢˜"
    elif options:
        detected = "å•é€‰é¢˜"
    type_line = f"å½“å‰é¢˜å‹ï¼š{detected}\n" if detected else ""
    use_selective = bool(detected in ("å•é€‰é¢˜","å¤šé€‰é¢˜")) or bool(options)
    instruction = instruction_selective if use_selective else instruction_generic
    prompt = f"{instruction}\n{type_line}é¢˜ç›®ï¼š{q.get('question','')}" + opt_block + "\nä½ çš„ç­”æ¡ˆï¼š"
    return prompt

def build_prompt_freeform_strict(q):
    options = q.get('options', {})
    opt_lines = []
    if options:
        opt_lines = [
            f"A. {options.get('A', '')}",
            f"B. {options.get('B', '')}",
            f"C. {options.get('C', '')}",
            f"D. {options.get('D', '')}",
        ]
    opt_block = ("\né€‰é¡¹ï¼š\n" + "\n".join(opt_lines)) if opt_lines else ""
    qtext = q.get('question') or q.get('prompt') or ''
    lt = str(qtext).lower()
    detected = None
    if ("å¤šé€‰é¢˜" in str(qtext)) or ("multiple-choice" in lt) or ("multiple choice" in lt):
        detected = "å¤šé€‰é¢˜"
    elif ("å•é€‰é¢˜" in str(qtext)) or ("single-choice" in lt) or ("single choice" in lt):
        detected = "å•é€‰é¢˜"
    elif ("åˆ¤æ–­é¢˜" in str(qtext)) or ("true/false" in lt) or ("true or false" in lt) or ("åˆ¤æ–­" in str(qtext)):
        detected = "åˆ¤æ–­é¢˜"
    elif options:
        detected = "å•é€‰é¢˜"
    type_line = f"å½“å‰é¢˜å‹ï¼š{detected}\n" if detected else ""
    instruction = (
        "è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦è§£é‡Šã€‚\n"
        "è‹¥ä¸ºé€‰æ‹©é¢˜ï¼Œä»…è¾“å‡ºå­—æ¯ï¼›è‹¥ä¸ºå¤šé€‰ï¼Œè¾“å‡ºA,B,Cï¼›\n"
        "è‹¥ä¸ºåˆ¤æ–­é¢˜ï¼Œä»…è¾“å‡ºâ€˜å¯¹â€™æˆ–â€˜é”™â€™ï¼›\n"
        "ä»…è¾“å‡ºä¸€è¡Œç­”æ¡ˆã€‚\n"
    )
    prompt = f"{instruction}\n{type_line}é¢˜ç›®ï¼š{qtext}" + opt_block + "\nä½ çš„ç­”æ¡ˆï¼š"
    return prompt

def build_prompt_freeform_stricter(q):
    options = q.get('options', {})
    opt_lines = []
    if options:
        opt_lines = [
            f"A. {options.get('A', '')}",
            f"B. {options.get('B', '')}",
            f"C. {options.get('C', '')}",
            f"D. {options.get('D', '')}",
        ]
    opt_block = ("\né€‰é¡¹ï¼š\n" + "\n".join(opt_lines)) if opt_lines else ""
    qtext = q.get('question') or q.get('prompt') or ''
    instruction = (
        "è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦è§£é‡Šã€‚\n"
        "ä»…è¾“å‡ºä¸€è¡Œä¸­æ–‡çŸ­è¯­ä½œä¸ºç­”æ¡ˆã€‚\n"
        "ä¸å¾—è¾“å‡ºå•ä¸ªå­—æ¯A/B/C/Dã€‚\n"
    )
    prompt = f"{instruction}\né¢˜ç›®ï¼š{qtext}" + opt_block + "\nä½ çš„ç­”æ¡ˆï¼š"
    return prompt

def extract_text_answer(text, q=None):
    if not text:
        return ""
    s = str(text).strip()
    s = re.sub(r"(?is)<think[\s\S]*?</think>", "", s)
    s = s.strip('`').strip('"')
    s = re.sub(r"^```[\s\S]*?```", lambda m: m.group(0).strip('`'), s)
    def try_json_payload(x):
        try:
            obj = json.loads(x)
            for k in ('answer','final_answer','pred','label','ç»“æœ','ç­”æ¡ˆ'):
                if k in obj and isinstance(obj[k], str):
                    return obj[k].strip()
        except:
            pass
        return None
    j = None
    if '{' in s and '}' in s:
        start = s.find('{')
        end = s.rfind('}')
        j = try_json_payload(s[start:end+1])
        if j:
            s = j
    t = (q.get('prompt') or q.get('question') or '').lower() if isinstance(q, dict) else ''
    allow_letters = False
    if isinstance(q, dict):
        opts = q.get('options') or {}
        if opts:
            allow_letters = True
        if ('å•é€‰é¢˜' in t) or ('å¤šé€‰é¢˜' in t) or ('single-choice' in t) or ('single choice' in t) or ('multiple-choice' in t) or ('multiple choice' in t) or ('å•é€‰' in t) or ('å¤šé€‰' in t):
            allow_letters = True
    is_judgement = ('åˆ¤æ–­é¢˜' in t) or ('true/false' in t) or ('true or false' in t) or ('åˆ¤æ–­' in t)
    if is_judgement:
        if re.search(r"(?is)true|æ­£ç¡®|æ˜¯|å¯¹", s):
            return 'å¯¹'
        if re.search(r"(?is)false|é”™è¯¯|å¦|é”™", s):
            return 'é”™'
    if allow_letters and (('å¤šé€‰é¢˜' in t) or ('multiple-choice' in t) or ('å¤šé€‰' in t)):
        lines_all = [ln.strip() for ln in s.splitlines() if ln.strip()]
        for ln in reversed(lines_all):
            if any(k in ln for k in ['é€‰é¡¹','ä½ çš„ç­”æ¡ˆ','Final Answer','ç­”æ¡ˆ']):
                continue
            if re.fullmatch(r"(?is)[A-D,\s]+", ln):
                letters = re.findall(r"[A-D]", ln, flags=re.IGNORECASE)
                if letters:
                    uniq = []
                    for ch in [c.upper() for c in letters]:
                        if ch not in uniq:
                            uniq.append(ch)
                    return ",".join(uniq)
    if allow_letters and (('å•é€‰é¢˜' in t) or ('single-choice' in t) or ('å•é€‰' in t)):
        lines_all = [ln.strip() for ln in s.splitlines() if ln.strip()]
        for ln in reversed(lines_all):
            if any(k in ln for k in ['é€‰é¡¹','ä½ çš„ç­”æ¡ˆ','Final Answer','ç­”æ¡ˆ']):
                continue
            mm = re.fullmatch(r"\s*([ABCD])\s*", ln, flags=re.IGNORECASE)
            if mm:
                return mm.group(1).upper()
    m = re.search(r"(?is)(?:æœ€ç»ˆç­”æ¡ˆ|Final\s*Answer|Answer|ç­”æ¡ˆ)[^\n\r]*[:ï¼š]\s*([\s\S]+)$", s)
    if m:
        tail = m.group(1).strip()
        lines_tail = [ln.strip() for ln in tail.splitlines() if ln.strip()]
        invalid_tokens = ['è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆ', 'ä»…è¾“å‡ºä¸€è¡Œç­”æ¡ˆ', 'ä¸è¦è§£é‡Š', 'å½“å‰é¢˜å‹', 'æœ€åä¸€è¡Œä½¿ç”¨', 'è¯·åœ¨æ­¤å¤„å¡«å†™', 'å¡«å†™ç­”æ¡ˆ', 'è¯·å¡«å†™', 'ç”¨ä¸­æ–‡å¡«å†™', 'ç”¨å­—æ¯è¡¨ç¤º', 'è¯·ç›´æ¥è¾“å‡ºç­”æ¡ˆ', 'ç›´æ¥å¡«å…¥ç­”æ¡ˆ', 'ä½ çš„ç­”æ¡ˆ', 'Final Answer', 'ç­”æ¡ˆ', 'ç­”æ¡ˆï¼š', 'é¢˜ç›®', 'é€‰é¡¹']
        for first in lines_tail:
            if any(tok in first for tok in invalid_tokens):
                continue
            if is_judgement:
                if re.search(r"(?is)true|æ­£ç¡®|æ˜¯|å¯¹", first):
                    return 'å¯¹'
                if re.search(r"(?is)false|é”™è¯¯|å¦|é”™", first):
                    return 'é”™'
                mmj = re.fullmatch(r"\s*([ABCD])\s*", first, flags=re.IGNORECASE)
                if mmj and isinstance(q, dict):
                    chj = mmj.group(1).upper()
                    o = q.get('options') or {}
                    a = str(o.get('A','')).lower()
                    b = str(o.get('B','')).lower()
                    def _is_true(x):
                        return bool(re.search(r"(?is)true|æ­£ç¡®|æ˜¯|å¯¹", x))
                    def _is_false(x):
                        return bool(re.search(r"(?is)false|é”™è¯¯|å¦|é”™", x))
                    if _is_true(a) and _is_false(b):
                        if chj == 'A':
                            return 'å¯¹'
                        if chj == 'B':
                            return 'é”™'
                    if _is_true(b) and _is_false(a):
                        if chj == 'B':
                            return 'å¯¹'
                        if chj == 'A':
                            return 'é”™'
            if allow_letters and (('å¤šé€‰é¢˜' in t) or ('multiple-choice' in t) or ('å¤šé€‰' in t)):
                letters = re.findall(r"[A-D]", first, flags=re.IGNORECASE)
                if letters:
                    uniq = []
                    for ch in [c.upper() for c in letters]:
                        if ch not in uniq:
                            uniq.append(ch)
                    return ",".join(uniq)
            if allow_letters and (('å•é€‰é¢˜' in t) or ('single-choice' in t) or ('å•é€‰' in t)):
                mm = re.search(r"\b([ABCD])\b", first, flags=re.IGNORECASE)
                if mm:
                    return mm.group(1).upper()
            if first in ('å¯¹','é”™'):
                return first
            if (not is_judgement) and allow_letters and first in ('A','B','C','D'):
                return first
            if (not is_judgement) and allow_letters:
                mm2 = re.search(r"\b([ABCD])\b", first, flags=re.IGNORECASE)
                if mm2:
                    return mm2.group(1).upper()
            if re.search(r"(?is)true|æ­£ç¡®|æ˜¯|å¯¹", first):
                return 'å¯¹'
            if re.search(r"(?is)false|é”™è¯¯|å¦|é”™", first):
                return 'é”™'
            return first[:64]
        if (not is_judgement) and allow_letters:
            mm_all = re.search(r"\b([ABCD])\b", tail, flags=re.IGNORECASE)
            if mm_all:
                return mm_all.group(1).upper()
        if re.search(r"(?is)true|æ­£ç¡®|æ˜¯|å¯¹", tail):
            return 'å¯¹'
        if re.search(r"(?is)false|é”™è¯¯|å¦|é”™", tail):
            return 'é”™'
        return ''
    s2 = s.strip()
    if s2 in ('å¯¹','é”™'):
        return s2
    if (not is_judgement) and allow_letters and s2 in ('A','B','C','D'):
        return s2
    lines = [ln.strip() for ln in s2.splitlines() if ln.strip()]
    for ln in lines:
        if any(k in ln for k in ['è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆ', 'ä»…è¾“å‡ºä¸€è¡Œç­”æ¡ˆ', 'ä¸è¦è§£é‡Š', 'å½“å‰é¢˜å‹', 'æœ€åä¸€è¡Œä½¿ç”¨']):
            continue
        if re.fullmatch(r"[\s\-_=ï¼ˆ()ï¼‰ã€ã€‘<>ã€Šã€‹~Â·.,;:ï¼Œã€‚ï¼›ï¼š!?ï¼ï¼Ÿ]+", ln):
            continue
        if re.search(r"(?is)è¯·å¡«å†™|å¡«å†™ç­”æ¡ˆ|è¯·åœ¨æ­¤å¤„å¡«å†™|ç”¨ä¸­æ–‡å¡«å†™|ç”¨å­—æ¯è¡¨ç¤º|è¯·ç›´æ¥è¾“å‡ºç­”æ¡ˆ|ç›´æ¥å¡«å…¥ç­”æ¡ˆ|ç­”æ¡ˆï¼š|^ç­”æ¡ˆ$", ln):
            continue
        if ln in ('å¯¹','é”™'):
            return ln
        if (not is_judgement) and allow_letters and ln in ('A','B','C','D'):
            return ln
        if (not is_judgement) and allow_letters:
            mm = re.search(r"\b([ABCD])\b", ln, flags=re.IGNORECASE)
            if mm:
                return mm.group(1).upper()
        if re.search(r"(?is)true|æ­£ç¡®|æ˜¯|å¯¹", ln):
            return 'å¯¹'
        if re.search(r"(?is)false|é”™è¯¯|å¦|é”™", ln):
            return 'é”™'
        if not any(k in ln for k in ['ä½ çš„ç­”æ¡ˆ', 'é¢˜ç›®', 'é€‰é¡¹', 'Final Answer', 'ç­”æ¡ˆ']):
            return ln[:64]
    if (not lines) or all(
        (any(k in ln for k in ['è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆ', 'ä»…è¾“å‡ºä¸€è¡Œç­”æ¡ˆ', 'ä¸è¦è§£é‡Š', 'å½“å‰é¢˜å‹', 'æœ€åä¸€è¡Œä½¿ç”¨']) or
         re.fullmatch(r"[\s\-_=ï¼ˆ()ï¼‰ã€ã€‘<>ã€Šã€‹~Â·.,;:ï¼Œã€‚ï¼›ï¼š!?ï¼ï¼Ÿ]+", ln) or
         re.search(r"(?is)è¯·å¡«å†™|å¡«å†™ç­”æ¡ˆ|è¯·åœ¨æ­¤å¤„å¡«å†™", ln))
        for ln in lines
    ):
        return ''
    return (lines[0][:64])


def call_ollama_generate(base_url, model, prompt, temperature=0.7, retry=3, timeout=60):
    url = base_url.rstrip('/') + '/api/generate'
    payload = {
        'model': model,
        'prompt': prompt,
        'stream': False,
        'options': {
            'temperature': float(temperature)
        }
    }
    data = json.dumps(payload).encode('utf-8')

    last_err = None
    for attempt in range(1, retry + 1):
        try:
            req = request.Request(url, data=data, headers={'Content-Type': 'application/json'})
            with request.urlopen(req, timeout=timeout) as resp:
                text = resp.read().decode('utf-8', errors='replace')
                obj = json.loads(text)
                return obj.get('response', '')
        except error.HTTPError as e:
            last_err = f"HTTPError {e.code}: {e.read().decode('utf-8', errors='replace')}"
        except error.URLError as e:
            last_err = f"URLError: {e.reason}"
        except Exception as e:
            last_err = f"Error: {e}"
        # backoff
        sleep_s = min(2 ** (attempt - 1), 8)
        time.sleep(sleep_s)
    raise RuntimeError(f"è°ƒç”¨Ollamaå¤±è´¥: {last_err}")


def call_vllm_generate(base_url, model, prompt, temperature=0.7, api_key=None, retry=3, timeout=60, max_tokens=8192, stop=None):
    """è°ƒç”¨vLLMçš„OpenAIå…¼å®¹API"""
    url = base_url.rstrip('/') + '/v1/completions'
    payload = {
        'model': model,
        'prompt': prompt,
        'temperature': float(temperature),
        'max_tokens': int(max_tokens),
    }
    if stop is not None:
        payload['stop'] = stop
    data = json.dumps(payload).encode('utf-8')
    
    # æ„å»ºè¯·æ±‚å¤´
    headers = {'Content-Type': 'application/json'}
    if api_key:
        headers['Authorization'] = f'Bearer {api_key}'

    last_err = None
    for attempt in range(1, retry + 1):
        try:
            req = request.Request(url, data=data, headers=headers)
            with request.urlopen(req, timeout=timeout) as resp:
                text = resp.read().decode('utf-8', errors='replace')
                obj = json.loads(text)
                choices = obj.get('choices', [])
                if choices:
                    return choices[0].get('text', '')
                return ''
        except error.HTTPError as e:
            last_err = f"HTTPError {e.code}: {e.read().decode('utf-8', errors='replace')}"
        except error.URLError as e:
            last_err = f"URLError: {e.reason}"
        except Exception as e:
            last_err = f"Error: {e}"
        # backoff
        sleep_s = min(2 ** (attempt - 1), 8)
        time.sleep(sleep_s)
    raise RuntimeError(f"è°ƒç”¨vLLMå¤±è´¥: {last_err}")


def call_vllm_generate_chat(base_url, model, prompt, temperature=0.7, api_key=None, retry=3, timeout=60, max_tokens=8192, stop=None):
    url = base_url.rstrip('/') + '/v1/chat/completions'
    payload = {
        'model': model,
        'messages': [
            {
                'role': 'user',
                'content': prompt
            }
        ],
        'temperature': float(temperature),
        'max_tokens': int(max_tokens),
    }
    if stop is not None:
        payload['stop'] = stop
    data = json.dumps(payload).encode('utf-8')
    headers = {'Content-Type': 'application/json'}
    if api_key:
        headers['Authorization'] = f'Bearer {api_key}'
    last_err = None
    for attempt in range(1, retry + 1):
        try:
            req = request.Request(url, data=data, headers=headers)
            with request.urlopen(req, timeout=timeout) as resp:
                text = resp.read().decode('utf-8', errors='replace')
                obj = json.loads(text)
                choices = obj.get('choices', [])
                if choices:
                    message = choices[0].get('message', {})
                    return message.get('content', '')
                return ''
        except error.HTTPError as e:
            last_err = f"HTTPError {e.code}: {e.read().decode('utf-8', errors='replace')}"
        except error.URLError as e:
            last_err = f"URLError: {e.reason}"
        except Exception as e:
            last_err = f"Error: {e}"
        sleep_s = min(2 ** (attempt - 1), 8)
        time.sleep(sleep_s)
    raise RuntimeError(f"è°ƒç”¨vLLM Chatå¤±è´¥: {last_err}")

 


def extract_choice(text):
    if not text:
        return None
    text = re.sub(r"(?is)<think[\s\S]*?</think>", "", str(text))
    m = re.search(r"(?:æœ€ç»ˆç­”æ¡ˆ|Final\s+Answer|ç­”æ¡ˆ)[^\n\r]*[:ï¼š]\s*([ABCD])\b", text, flags=re.IGNORECASE)
    if m:
        return m.group(1).upper()
    lines = text.splitlines()
    for line in reversed(lines):
        mm = re.match(r"\s*([ABCD])\s*$", line, flags=re.IGNORECASE)
        if mm:
            return mm.group(1).upper()
    s = text.strip()
    if re.fullmatch(r"[ABCD]", s, flags=re.IGNORECASE):
        return s.upper()
    return None

def extract_think(text):
    if not text:
        return ''
    s = str(text)
    m = re.search(r"(?is)<think[\s\S]*?</think>", s)
    if not m:
        m = re.search(r"(?is)<analysis[\s\S]*?</analysis>", s)
    if m:
        t = m.group(0)
        t = re.sub(r"(?is)</?think>", "", t)
        t = re.sub(r"(?is)</?analysis>", "", t)
        return t.strip()
    idx = re.search(r"(?is)(æœ€ç»ˆç­”æ¡ˆ|Final\s+Answer|ç­”æ¡ˆ)[^\n\r]*[:ï¼š]", s)
    if idx:
        return s[:idx.start()].strip()
    return ''


# å…¨å±€å˜é‡ç”¨äºåŠ¨ç”»æ•ˆæœ
_spinner_chars = ['â ‹', 'â ™', 'â ¹', 'â ¸', 'â ¼', 'â ´', 'â ¦', 'â §', 'â ‡', 'â ']
_spinner_index = 0
_progress_call_count = 0

# çº¿ç¨‹å®‰å…¨çš„è¿›åº¦ç®¡ç†å™¨
class ThreadSafeProgress:
    def __init__(self, total):
        self.total = total
        self.completed = 0
        self.correct = 0
        self.lock = threading.Lock()
        self.results = []
        
    def update(self, is_correct, result_data):
        with self.lock:
            self.completed += 1
            if is_correct:
                self.correct += 1
            self.results.append(result_data)
            rt = result_data.get('think') or ''
            if rt:
                print(f"\nğŸ§  æ¨ç†ï¼š{rt.strip()}")
            if result_data.get('show_full'):
                full = result_data.get('model_response') or ''
                if full:
                    print(f"\nğŸ“œ å®Œæ•´å›ç­”ï¼š\n{full.strip()}")
            # å®æ—¶æ˜¾ç¤ºè¿›åº¦
            print(f"\n[{self.completed}/{self.total}] ğŸ“ é¢˜ç›®ID: {result_data.get('id')}  ğŸ¯ æ ‡å‡†ç­”æ¡ˆ: {result_data.get('answer')}  ğŸ¤– æ¨¡å‹ç­”æ¡ˆ: {result_data.get('model_choice') or 'N/A'}  {'âœ… æ­£ç¡®' if is_correct else 'âŒ é”™è¯¯'}")
            print_progress(self.completed, self.total, self.correct)
            
    def get_stats(self):
        with self.lock:
            return self.completed, self.correct, self.results.copy()


def process_single_question(question_data, args, progress_manager):
    """å¤„ç†å•ä¸ªé¢˜ç›®çš„å‡½æ•°ï¼Œç”¨äºå¤šçº¿ç¨‹è°ƒç”¨"""
    idx, q = question_data
    prompt = build_prompt(q)
    if args.show_think:
        opts = q.get('options', {})
        prompt = (
            "è¯·å…ˆåœ¨<think></think>æ ‡ç­¾ä¸­è¯¦ç»†å†™å‡ºä½ çš„æ¨ç†è¿‡ç¨‹ï¼Œä¸è¦çœç•¥æˆ–éšè—ã€‚\n"
            "æœ€åä¸¥æ ¼åªè¾“å‡ºä¸€è¡Œï¼š\nFinal Answer: <A/B/C/D>\n"
            f"é¢˜ç›®ï¼š{q.get('question','')}\né€‰é¡¹ï¼š\nA. {opts.get('A','')}\nB. {opts.get('B','')}\nC. {opts.get('C','')}\nD. {opts.get('D','')}\nä½ çš„ç­”æ¡ˆï¼š"
        )
    model_resp = ''
    model_choice = None
    think_text = ''
    
    max_retries = 3
    retry_delay = 1.0
    for attempt in range(max_retries):
        try:
            if args.api_type == 'vllm':
                mt = args.think_max_tokens if args.show_think else 8192
                model_resp = call_vllm_generate_chat(args.base_url, args.model, prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=mt, stop=None)
                if not model_resp:
                    model_resp = call_vllm_generate(args.base_url, args.model, prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=mt, stop=None)
            else:
                model_resp = call_ollama_generate(args.base_url, args.model, prompt, temperature=args.temperature)
            model_choice = extract_choice(model_resp)
            think_text = extract_think(model_resp)
            if model_choice:
                break
            if args.show_think:
                if attempt < max_retries - 1:
                    time.sleep(retry_delay + random.uniform(0, 1))
                    retry_delay *= 1.5
                continue
            strict_prompt = (
                "ä»…è¾“å‡ºä»¥ä¸‹æ ¼å¼çš„å”¯ä¸€ä¸€è¡Œï¼š\n"
                "Final Answer: <A/B/C/D>\n"
                f"é¢˜ç›®ï¼š{q.get('question','')}\né€‰é¡¹ï¼š\nA. {q.get('options',{}).get('A','')}\nB. {q.get('options',{}).get('B','')}\nC. {q.get('options',{}).get('C','')}\nD. {q.get('options',{}).get('D','')}\nä½ çš„ç­”æ¡ˆï¼š"
            )
            if args.api_type == 'vllm':
                model_resp = call_vllm_generate_chat(args.base_url, args.model, strict_prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=8192, stop=['\n','\r\n'])
                if not model_resp:
                    model_resp = call_vllm_generate(args.base_url, args.model, strict_prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=8192, stop=['\n','\r\n'])
            else:
                model_resp = call_ollama_generate(args.base_url, args.model, strict_prompt, temperature=args.temperature)
            model_choice = extract_choice(model_resp)
            think_text = extract_think(model_resp)
            if model_choice:
                break
            if attempt < max_retries - 1:
                time.sleep(retry_delay + random.uniform(0, 1))
                retry_delay *= 1.5
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(retry_delay + random.uniform(0, 1))
                retry_delay *= 1.5
            else:
                model_resp = f"<âŒ è°ƒç”¨å¤±è´¥ (é‡è¯•{max_retries}æ¬¡): {e}>"
                model_choice = None
    
    answer = q.get('answer', '').strip().upper() if isinstance(q.get('answer'), str) else ''
    is_correct = (model_choice == answer)
    
    # æ„å»ºç»“æœæ•°æ®
    opt_texts = q.get('options', {})
    model_choice_text = opt_texts.get(model_choice, '') if model_choice else ''
    answer_text = opt_texts.get(answer, '')
    
    result_data = {
        'id': q.get('id'),
        'question': q.get('question'),
        'options': opt_texts,
        'answer': answer,
        'answer_text': answer_text,
        'model_response': model_resp,
        'think': ((think_text if think_text else model_resp) if args.show_think else ''),
        'model_choice': model_choice,
        'model_choice_text': model_choice_text,
        'is_correct': is_correct,
        'show_full': args.show_full,
    }
    
    # æ›´æ–°è¿›åº¦
    progress_manager.update(is_correct, result_data)
    
    return result_data

def process_single_question_freeform(question_data, args):
    idx, q = question_data
    blank_ids = {"1751","1761","1762","1763","1764","1766","1767","1769","1770","2852","3127","3129"}
    if str(q.get('id')) in blank_ids:
        return {'question_id': str(q.get('id')), 'answer': '', 'raw': ''}
    prompt = build_prompt_freeform(q)
    if args.show_think:
        qtext = q.get('question') or q.get('prompt') or ''
        options = q.get('options') or {}
        opt_block = ("\né€‰é¡¹ï¼š\nA. " + str(options.get('A','')) + "\nB. " + str(options.get('B','')) + "\nC. " + str(options.get('C','')) + "\nD. " + str(options.get('D',''))) if options else ''
        prompt = (
            "è¯·å…ˆåœ¨<think></think>æ ‡ç­¾ä¸­å®Œæ•´å†™å‡ºä½ çš„æ¨ç†è¿‡ç¨‹ã€‚\n"
            "æœ€åä¸¥æ ¼åªè¾“å‡ºä¸€è¡Œï¼š\nFinal Answer: <ç­”æ¡ˆ>\n"
            f"é¢˜ç›®ï¼š{qtext}" + opt_block + "\nä½ çš„ç­”æ¡ˆï¼š"
        )
    model_resp = ''
    raw_used = ''
    max_retries = 3
    retry_delay = 1.0
    for attempt in range(max_retries):
        try:
            if args.api_type == 'vllm':
                mt = args.think_max_tokens if args.show_think else 8192
                stops = None if ('instruct' in str(args.model).lower()) else ["ä½ çš„ç­”æ¡ˆï¼š"]
                model_resp = call_vllm_generate(args.base_url, args.model, prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=mt, stop=stops)
                if not model_resp:
                    model_resp = call_vllm_generate_chat(args.base_url, args.model, prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=mt, stop=stops)
            else:
                model_resp = call_ollama_generate(args.base_url, args.model, prompt, temperature=args.temperature)
            raw_used = model_resp
            break
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(retry_delay + random.uniform(0, 1))
                retry_delay *= 1.5
            else:
                model_resp = ''
    think_text = extract_think(model_resp)
    if args.show_think:
        print(f"\nğŸ§  æ¨ç†ï¼š{(think_text if think_text else model_resp).strip()}")
    if args.show_full:
        if raw_used:
            print(f"\nğŸ“œ å®Œæ•´å›ç­”ï¼š\n{raw_used.strip()}")
        elif model_resp:
            print(f"\nğŸ“œ å®Œæ•´å›ç­”ï¼š\n{model_resp.strip()}")
    answer_text = extract_text_answer(model_resp, q)
    if not answer_text:
        strict_prompt = build_prompt_freeform_strict(q)
        try:
            if args.api_type == 'vllm':
                stops2 = ["\n","\r\n"] if ('instruct' in str(args.model).lower()) else ["ä½ çš„ç­”æ¡ˆï¼š"]
                model_resp2 = call_vllm_generate(args.base_url, args.model, strict_prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=128, stop=stops2)
                if not model_resp2:
                    model_resp2 = call_vllm_generate_chat(args.base_url, args.model, strict_prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=128, stop=stops2)
            else:
                model_resp2 = call_ollama_generate(args.base_url, args.model, strict_prompt, temperature=args.temperature)
        except Exception:
            model_resp2 = ''
        answer_text = extract_text_answer(model_resp2, q)
        if args.show_full and model_resp2:
            print(f"\nğŸ“œ å®Œæ•´å›ç­”ï¼š\n{model_resp2.strip()}")
        if answer_text:
            raw_used = model_resp2
    t_multi = str((q.get('prompt') or q.get('question') or '')).lower()
    is_multi = ('å¤šé€‰' in t_multi) or ('multiple-choice' in t_multi) or ('multiple choice' in t_multi)
    if is_multi and answer_text in ('A','B','C','D'):
        strict_prompt_multi = build_prompt_freeform_strict(q)
        try:
            if args.api_type == 'vllm':
                stopsm = ["\n","\r\n"] if ('instruct' in str(args.model).lower()) else ["ä½ çš„ç­”æ¡ˆï¼š"]
                model_resp_m = call_vllm_generate(args.base_url, args.model, strict_prompt_multi, temperature=args.temperature, api_key=args.api_key, max_tokens=128, stop=stopsm)
                if not model_resp_m:
                    model_resp_m = call_vllm_generate_chat(args.base_url, args.model, strict_prompt_multi, temperature=args.temperature, api_key=args.api_key, max_tokens=128, stop=stopsm)
            else:
                model_resp_m = call_ollama_generate(args.base_url, args.model, strict_prompt_multi, temperature=args.temperature)
        except Exception:
            model_resp_m = ''
        parsed_m = extract_text_answer(model_resp_m, q)
        if parsed_m:
            answer_text = parsed_m
            raw_used = model_resp_m
    if answer_text in ('A','B','C','D'):
        t = (q.get('prompt') or q.get('question') or '').lower()
        opts = q.get('options') or {}
        if not (opts or ('å•é€‰' in t) or ('å¤šé€‰' in t) or ('single-choice' in t) or ('multiple-choice' in t)):
            stricter_prompt = build_prompt_freeform_stricter(q)
            try:
                if args.api_type == 'vllm':
                    model_resp3 = call_vllm_generate(args.base_url, args.model, stricter_prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=64, stop=["\n","\r\n"])
                    if not model_resp3:
                        model_resp3 = call_vllm_generate_chat(args.base_url, args.model, stricter_prompt, temperature=args.temperature, api_key=args.api_key, max_tokens=64, stop=["\n","\r\n"])
                else:
                    model_resp3 = call_ollama_generate(args.base_url, args.model, stricter_prompt, temperature=args.temperature)
            except Exception:
                model_resp3 = ''
            answer_text = extract_text_answer(model_resp3, q)
            if args.show_full and model_resp3:
                print(f"\nğŸ“œ å®Œæ•´å›ç­”ï¼š\n{model_resp3.strip()}")
            if answer_text:
                raw_used = model_resp3
    return {'question_id': str(q.get('id')), 'answer': answer_text, 'raw': (raw_used or model_resp)}

def print_progress(done, total, correct):
    global _spinner_index, _progress_call_count
    _progress_call_count += 1
    
    # ANSIé¢œè‰²ä»£ç  - æ‰©å±•å½©è™¹è‰²è°±
    class Colors:
        RESET = '\033[0m'
        BOLD = '\033[1m'
        DIM = '\033[2m'
        ITALIC = '\033[3m'
        UNDERLINE = '\033[4m'
        
        # åŸºç¡€é¢œè‰²
        BLACK = '\033[30m'
        RED = '\033[31m'
        GREEN = '\033[32m'
        YELLOW = '\033[33m'
        BLUE = '\033[34m'
        MAGENTA = '\033[35m'
        CYAN = '\033[36m'
        WHITE = '\033[37m'
        
        # äº®è‰²ç³»åˆ—
        BRIGHT_BLACK = '\033[90m'
        BRIGHT_RED = '\033[91m'
        BRIGHT_GREEN = '\033[92m'
        BRIGHT_YELLOW = '\033[93m'
        BRIGHT_BLUE = '\033[94m'
        BRIGHT_MAGENTA = '\033[95m'
        BRIGHT_CYAN = '\033[96m'
        BRIGHT_WHITE = '\033[97m'
        
        # 256è‰²æ¨¡å¼ - å½©è™¹è‰²è°±
        ORANGE = '\033[38;5;208m'        # æ©™è‰²
        DARK_ORANGE = '\033[38;5;202m'   # æ·±æ©™è‰²
        PINK = '\033[38;5;205m'          # ç²‰è‰²
        PURPLE = '\033[38;5;129m'        # ç´«è‰²
        DARK_PURPLE = '\033[38;5;93m'    # æ·±ç´«è‰²
        ROYAL_BLUE = '\033[38;5;54m'     # çš‡å®¶è“
        LIME = '\033[38;5;154m'          # é’æŸ è‰²
        SEA_GREEN = '\033[38;5;48m'      # æµ·ç»¿è‰²
        TURQUOISE = '\033[38;5;51m'      # é’ç»¿è‰²
        SKY_BLUE = '\033[38;5;117m'      # å¤©è“è‰²
        VIOLET = '\033[38;5;177m'        # ç´«ç½—å…°è‰²
        GOLD = '\033[38;5;220m'          # é‡‘è‰²
        CORAL = '\033[38;5;203m'         # çŠç‘šè‰²
        NEON_GREEN = '\033[38;5;46m'     # éœ“è™¹ç»¿
        NEON_PINK = '\033[38;5;198m'     # éœ“è™¹ç²‰
        
        # RGBé¢œè‰²ï¼ˆçœŸå½©è‰²ï¼‰
        NEON_GREEN = '\033[38;2;57;255;20m'
        NEON_BLUE = '\033[38;2;77;77;255m'
        NEON_PINK = '\033[38;2;255;20;147m'
        ELECTRIC_PURPLE = '\033[38;2;191;0;255m'
        CYBER_CYAN = '\033[38;2;0;255;255m'
    
    bar_len = 50
    ratio = 0 if total == 0 else done / total
    filled = int(ratio * bar_len)
    percent = ratio * 100
    accuracy = (correct / done * 100) if done > 0 else 0
    
    # åŠ¨æ€æ—‹è½¬æŒ‡ç¤ºå™¨
    spinner = _spinner_chars[_spinner_index % len(_spinner_chars)]
    _spinner_index += 1
    
    # æ ¹æ®å‡†ç¡®ç‡é€‰æ‹©é¢œè‰²ä¸»é¢˜å’Œè¡¨æƒ…
    if accuracy >= 95:
        emoji = "ğŸ†"
        bar_color = Colors.NEON_GREEN
        text_color = Colors.BRIGHT_GREEN
        accent_color = Colors.GOLD
    elif accuracy >= 90:
        emoji = "ğŸ’"
        bar_color = Colors.BRIGHT_GREEN
        text_color = Colors.GREEN
        accent_color = Colors.LIME
    elif accuracy >= 85:
        emoji = "ğŸŒŸ"
        bar_color = Colors.LIME
        text_color = Colors.GREEN
        accent_color = Colors.SEA_GREEN
    elif accuracy >= 80:
        emoji = "âœ¨"
        bar_color = Colors.CYAN
        text_color = Colors.BRIGHT_CYAN
        accent_color = Colors.TURQUOISE
    elif accuracy >= 75:
        emoji = "ğŸ“Š"
        bar_color = Colors.CYAN
        text_color = Colors.BRIGHT_CYAN
        accent_color = Colors.SKY_BLUE
    elif accuracy >= 70:
        emoji = "ğŸ”µ"
        bar_color = Colors.BRIGHT_BLUE
        text_color = Colors.ROYAL_BLUE
        accent_color = Colors.BLUE
    elif accuracy >= 65:
        emoji = "ğŸ’œ"
        bar_color = Colors.PURPLE
        text_color = Colors.PURPLE
        accent_color = Colors.VIOLET
    elif accuracy >= 60:
        emoji = "âš¡"
        bar_color = Colors.BRIGHT_YELLOW
        text_color = Colors.GOLD
        accent_color = Colors.YELLOW
    elif accuracy >= 55:
        emoji = "ğŸŸ¡"
        bar_color = Colors.YELLOW
        text_color = Colors.ORANGE
        accent_color = Colors.GOLD
    elif accuracy >= 50:
        emoji = "ğŸŸ "
        bar_color = Colors.ORANGE
        text_color = Colors.ORANGE
        accent_color = Colors.DARK_ORANGE
    elif accuracy >= 40:
        emoji = "ğŸ”"
        bar_color = Colors.ORANGE
        text_color = Colors.DARK_ORANGE
        accent_color = Colors.RED
    elif accuracy >= 30:
        emoji = "ğŸ”¥"
        bar_color = Colors.NEON_PINK
        text_color = Colors.PINK
        accent_color = Colors.BRIGHT_MAGENTA
    else:
        emoji = "ğŸ’¥"
        bar_color = Colors.BRIGHT_RED
        text_color = Colors.RED
        accent_color = Colors.NEON_PINK
    
    # æŸ”å’Œè“è‰²ç³»æ¸å˜è‰²è°±æ•°ç»„ - ä»æµ…è“åˆ°æ·±è“çš„æ¸©å’Œæ¸å˜ï¼ˆ30ç§é¢œè‰²ï¼‰
    rainbow_colors = [
        '\033[38;5;195m',      # 1. ææµ…è“
        '\033[38;5;189m',      # 2. æµ…è“ç™½
        '\033[38;5;183m',      # 3. æ·¡è“
        '\033[38;5;177m',      # 4. æµ…è“ç´«
        '\033[38;5;171m',      # 5. è“ç´«
        '\033[38;5;165m',      # 6. æ·¡ç´«è“
        '\033[38;5;159m',      # 7. æµ…é’è“
        '\033[38;5;153m',      # 8. é’è“
        '\033[38;5;147m',      # 9. ç°è“
        '\033[38;5;141m',      # 10. ä¸­è“ç´«
        '\033[38;5;135m',      # 11. è“ç´«
        '\033[38;5;129m',      # 12. æ·±è“ç´«
        '\033[38;5;123m',      # 13. é’è“
        '\033[38;5;117m',      # 14. å¤©è“
        '\033[38;5;111m',      # 15. æµ…è“
        '\033[38;5;105m',      # 16. ä¸­è“
        '\033[38;5;99m',       # 17. è“ç°
        '\033[38;5;93m',       # 18. æ·±è“ç´«
        '\033[38;5;87m',       # 19. é’è“
        '\033[38;5;81m',       # 20. äº®é’è“
        '\033[38;5;75m',       # 21. è“
        '\033[38;5;69m',       # 22. ä¸­è“
        '\033[38;5;63m',       # 23. æ·±è“
        '\033[38;5;57m',       # 24. çš‡å®¶è“
        '\033[38;5;51m',       # 25. é’è‰²
        '\033[38;5;45m',       # 26. äº®é’
        '\033[38;5;39m',       # 27. è“é’
        '\033[38;5;33m',       # 28. æ·±é’è“
        '\033[38;5;27m',       # 29. æ·±è“
        '\033[38;5;21m'        # 30. æœ€æ·±è“
    ]
    
    # ç‚«é…·Unicodeå­—ç¬¦è¿›åº¦æ¡
    filled_chars = ['â–ˆ', 'â–“', 'â–’', 'â–‘']
    empty_char = 'â–‘'
    
    # åˆ›å»ºå½©è™¹æ¸å˜æ•ˆæœçš„è¿›åº¦æ¡
    bar_parts = []
    for i in range(bar_len):
        if i < filled:
            # æ ¹æ®è¿›åº¦æ¡ä½ç½®è®¡ç®—å½©è™¹é¢œè‰²ç´¢å¼•
            color_ratio = i / max(bar_len - 1, 1)  # é¿å…é™¤é›¶
            color_index = int(color_ratio * (len(rainbow_colors) - 1))
            color_index = min(color_index, len(rainbow_colors) - 1)
            
            # æ ¹æ®ä½ç½®é€‰æ‹©ä¸åŒçš„å¡«å……å­—ç¬¦åˆ›å»ºæ·±åº¦æ•ˆæœ
            if i < filled * 0.6:
                char = filled_chars[0]  # â–ˆ æœ€å®å¿ƒ
            elif i < filled * 0.8:
                char = filled_chars[1]  # â–“ è¾ƒå®å¿ƒ
            elif i < filled * 0.95:
                char = filled_chars[2]  # â–’ è¾ƒç©ºå¿ƒ
            else:
                char = filled_chars[3]  # â–‘ æœ€ç©ºå¿ƒ
            
            # åº”ç”¨å½©è™¹é¢œè‰²
            rainbow_color = rainbow_colors[color_index]
            bar_parts.append(f"{rainbow_color}{char}{Colors.RESET}")
        else:
            bar_parts.append(f"{Colors.DIM}{empty_char}{Colors.RESET}")
    
    bar = ''.join(bar_parts)
    
    # é—ªçƒæ•ˆæœï¼ˆæ¯6æ¬¡è°ƒç”¨é—ªçƒä¸€æ¬¡ï¼Œæ›´æŸ”å’Œï¼‰
    blink = Colors.BOLD if _progress_call_count % 12 < 6 else ''
    
    # æ„å»ºç‚«é…·çš„è¿›åº¦æ˜¾ç¤º
    progress_text = (
        f"\r{blink}{text_color}{spinner}{Colors.RESET} "
        f"{emoji} {Colors.BOLD}è¿›åº¦{Colors.RESET} "
        f"[{bar}] "
        f"{blink}{text_color}{percent:5.1f}%{Colors.RESET} "
        f"{Colors.DIM}|{Colors.RESET} "
        f"{accent_color}{done}{Colors.RESET}/{Colors.BOLD}{total}{Colors.RESET}"
    )
    
    sys.stdout.write(progress_text)
    sys.stdout.flush()


def generate_html_report(results, output_path, model, total_ms, only_errors=False, hide_question=False, summary_only=False):
    # Filter results if only_errors is True
    if only_errors:
        filtered_results = [r for r in results if r['is_correct'] is False]
        display_results = filtered_results
        report_title = "é”™è¯¯ç»“æœæŠ¥å‘Š"
        report_subtitle = f"ä»…æ˜¾ç¤ºé”™è¯¯ç­”é¢˜ Â· é”™è¯¯æ•°ï¼š{len(filtered_results)} / æ€»é¢˜æ•°ï¼š{len(results)}"
    else:
        display_results = results
        report_title = "å¤§æ¨¡å‹æµ‹è¯„æŠ¥å‘Š"
        report_subtitle = f"é¢˜ç›®æ•°ï¼š{len(results)}"
    
    total = len(results)
    correct = sum(1 for r in results if r['is_correct'] is True)
    accuracy = (correct / total * 100) if total else 0.0

    # Simple inline CSS
    css = """
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, 'Noto Sans', 'Liberation Sans', sans-serif; margin: 16px; color: #1f2937; }
    h1 { margin: 0 0 4px 0; font-size: 20px; }
    .sub { color: #6b7280; margin-top: 2px; font-size: 13px; }
    .card { background: #ffffff; border: 1px solid #e5e7eb; border-radius: 10px; padding: 12px; margin-top: 12px; box-shadow: 0 1px 2px rgba(0,0,0,0.04); }
    .stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(160px, 1fr)); gap: 12px; }
    .stat { background: #f9fafb; border: 1px solid #eef2f7; border-radius: 10px; padding: 12px; }
    .label { color: #6b7280; font-size: 11px; text-transform: uppercase; letter-spacing: .06em; }
    .value { font-size: 18px; font-weight: 700; margin-top: 4px; }
    .progress { height: 10px; background: #f3f4f6; border-radius: 8px; overflow: hidden; border: 1px solid #e5e7eb; }
    .progress > div { height: 100%; background: linear-gradient(90deg, #22c55e, #16a34a); width: 0%; }
    table { width: 100%; border-collapse: collapse; margin-top: 6px; }
    th, td { text-align: left; padding: 8px 6px; border-bottom: 1px solid #f1f5f9; vertical-align: top; }
    th { background: #f8fafc; color: #334155; }
    tr:hover { background: #f9fafb; }
    .ok { color: #16a34a; font-weight: 600; }
    .bad { color: #dc2626; font-weight: 600; }
    .muted { color: #64748b; font-size: 11px; }
    .badge { display: inline-block; padding: 2px 8px; border-radius: 999px; font-size: 12px; border: 1px solid #e5e7eb; background: #f8fafc; }
    """

    # Build rows
    rows_html = []
    for r in display_results:
        chosen_letter = r.get('model_choice') or '-'
        correct_letter = r.get('answer', '-')
        chosen_text = html.escape(r.get('model_choice_text') or '')
        correct_text = html.escape(r.get('answer_text') or '')
        status = '<span class="ok">æ­£ç¡®</span>' if r['is_correct'] else '<span class="bad">é”™è¯¯</span>'
        if hide_question:
            rows_html.append(
                f"<tr>"
                f"<td><span class='badge'>#{html.escape(str(r['id']))}</span></td>"
                f"<td><b>{html.escape(chosen_letter)}</b><div class='muted'>{chosen_text}</div></td>"
                f"<td><b>{html.escape(correct_letter)}</b><div class='muted'>{correct_text}</div></td>"
                f"<td>{status}</td>"
                f"</tr>"
            )
        else:
            q = html.escape(r['question'])
            rows_html.append(
                f"<tr>"
                f"<td><span class='badge'>#{html.escape(str(r['id']))}</span></td>"
                f"<td>{q}</td>"
                f"<td><b>{html.escape(chosen_letter)}</b><div class='muted'>{chosen_text}</div></td>"
                f"<td><b>{html.escape(correct_letter)}</b><div class='muted'>{correct_text}</div></td>"
                f"<td>{status}</td>"
                f"</tr>"
            )

    html_doc = f"""
<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>å¤§æ¨¡å‹æµ‹è¯„æŠ¥å‘Š - {html.escape(model)}</title>
  <style>{css}</style>
</head>
<body>
  <h1>{report_title}</h1>
  <div class="sub">æ¨¡å‹ï¼š<b>{html.escape(model)}</b> Â· {report_subtitle} Â· ç”¨æ—¶ï¼š{total_ms/1000:.1f}s</div>

  <div class="card">
    <div class="stats">
      <div class="stat">
        <div class="label">æ­£ç¡®ç‡</div>
        <div class="value">{accuracy:.2f}%</div>
        <div class="progress" aria-label="accuracy progress"><div style="width:{accuracy:.2f}%"></div></div>
      </div>
      <div class="stat">
        <div class="label">ç­”å¯¹ / æ€»æ•°</div>
        <div class="value">{correct} / {total}</div>
      </div>
      <div class="stat">
        <div class="label">é”™è¯¯</div>
        <div class="value">{total - correct}</div>
      </div>
    </div>
  </div>

  {'' if summary_only else (
    '<div class="card">'
    '<h3 style="margin-top:0;">è¯¦ç»†ç»“æœ</h3>'
    '<div style="max-height: 70vh; overflow: auto; border: 1px solid #e5e7eb; border-radius: 8px;">'
    '<table>'
    '<thead>'
    '<tr>'
    '<th style="width:70px;">ID</th>'
    f"{'' if hide_question else '<th>é¢˜ç›®</th>'}"
    '<th style="width:25%;">æ¨¡å‹ç­”æ¡ˆ</th>'
    '<th style="width:25%;">æ ‡å‡†ç­”æ¡ˆ</th>'
    '<th style="width:90px;">åˆ¤å®š</th>'
    '</tr>'
    '</thead>'
    '<tbody>'
    f"{''.join(rows_html)}"
    '</tbody>'
    '</table>'
    '</div>'
    '</div>'
  )}

  <p class="muted">æœ¬æŠ¥å‘Šç”±è‡ªåŠ¨è„šæœ¬ç”Ÿæˆã€‚</p>
</body>
</html>
"""

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_doc)

def generate_combined_summary(reports, output_path, model, total_ms):
    css = """
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial; margin: 16px; color: #1f2937; }
    h1 { margin: 0 0 4px 0; font-size: 20px; }
    .sub { color: #6b7280; margin-top: 2px; font-size: 13px; }
    .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(240px, 1fr)); gap: 12px; }
    .card { background: #ffffff; border: 1px solid #e5e7eb; border-radius: 10px; padding: 12px; }
    .title { font-weight: 600; color: #334155; margin-bottom: 6px; }
    .row { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; }
    .label { color: #6b7280; font-size: 12px; }
    .value { font-size: 18px; font-weight: 700; }
    .progress { height: 10px; background: #f3f4f6; border-radius: 8px; overflow: hidden; border: 1px solid #e5e7eb; margin-top: 6px; }
    .progress > div { height: 100%; background: linear-gradient(90deg, #22c55e, #16a34a); }
    """
    cards = []
    for r in reports:
        acc = (r['correct']/r['total']*100) if r['total'] else 0
        cards.append(
            f"<div class='card'>"
            f"<div class='title'>{r['name']}</div>"
            f"<div class='row'><div><div class='label'>æ­£ç¡®ç‡</div><div class='value'>{acc:.2f}%</div><div class='progress'><div style='width:{acc:.2f}%'></div></div></div>"
            f"<div><div class='label'>ç­”å¯¹ / æ€»æ•°</div><div class='value'>{r['correct']} / {r['total']}</div></div></div>"
            f"</div>"
        )
    html_doc = f"""
<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ç»¼åˆè¯„ä¼°æ¦‚è§ˆ - {html.escape(model)}</title>
  <style>{css}</style>
</head>
<body>
  <h1>ç»¼åˆè¯„ä¼°æ¦‚è§ˆ</h1>
  <div class="sub">æ¨¡å‹ï¼š<b>{html.escape(model)}</b> Â· ç”¨æ—¶ï¼š{total_ms/1000:.1f}s</div>
  <div class="grid">{''.join(cards)}</div>
  <p class="sub">æœ¬æ¦‚è§ˆæŠ¥å‘ŠåŒ…å«å¤šä¸ªé¢˜åº“çš„ç»Ÿè®¡æ‘˜è¦ã€‚</p>
</body>
</html>
"""
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_doc)


def main():
    parser = argparse.ArgumentParser(description='ä½¿ç”¨ Ollama æˆ– vLLM API å¯¹ data ç›®å½•é¢˜åº“è¿›è¡Œæµ‹è¯„ï¼Œç”Ÿæˆæ¦‚è§ˆæŠ¥å‘Šä¸ç­”æ¡ˆJSONã€‚')
    parser.add_argument('--model', default='llama3', help='æ¨¡å‹åç§°ï¼Œå¦‚: llama3, qwen2, mistral ç­‰')
    parser.add_argument('--api-type', choices=['ollama', 'vllm'], default='ollama', help='APIç±»å‹ï¼šollama æˆ– vllmï¼ˆé»˜è®¤ï¼šollamaï¼‰')
    parser.add_argument('--base-url', default='http://localhost:11434', help='APIæœåŠ¡åœ°å€ï¼ŒOllamaé»˜è®¤ä¸º http://localhost:11434ï¼ŒvLLMé»˜è®¤ä¸º http://localhost:8000')
    parser.add_argument('--api-key', help='APIå¯†é’¥ï¼ˆç”¨äº vLLMï¼ŒæŒ‰éœ€ï¼‰')
    parser.add_argument('--threads', type=int, default=4, help='å¹¶å‘çº¿ç¨‹æ•°é‡ï¼Œé»˜è®¤ 4')
    parser.add_argument('--temperature', type=float, default=0.7, help='é‡‡æ ·æ¸©åº¦ï¼Œé»˜è®¤ 0.7')
    parser.add_argument('--start', type=int, default=0, help='èµ·å§‹é¢˜ç›®ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰')
    parser.add_argument('--limit', type=int, default=0, help='é™åˆ¶é¢˜ç›®æ•°é‡ï¼ˆ0è¡¨ç¤ºä¸é™åˆ¶ï¼‰')
    parser.add_argument('--summary-only', action='store_true', help='HTMLæŠ¥å‘Šä»…æ˜¾ç¤ºç»Ÿè®¡æ¦‚è§ˆï¼Œä¸å±•ç¤ºé€é¢˜è¯¦ç»†ç»“æœ')
    parser.add_argument('--dataset', choices=['all', 'strike', 'cissp', 'cs_eval'], default='all', help='é€‰æ‹©è¯„æµ‹æ•°æ®é›†ï¼šall/strike/cissp/cs_eval')
    parser.add_argument('--show-think', action='store_true', help='ç»ˆç«¯è¾“å‡ºæ¨¡å‹æ€è€ƒè¿‡ç¨‹ï¼ˆ<think>å†…å®¹ï¼‰')
    parser.add_argument('--show-full', action='store_true', help='ç»ˆç«¯è¾“å‡ºæ¨¡å‹å®Œæ•´å›ç­”ï¼ˆåŸå§‹æ–‡æœ¬ï¼Œä¸è£å‰ªï¼‰')
    parser.add_argument('--think-max-tokens', type=int, default=8192, help='æ˜¾ç¤ºæ¨ç†æ—¶çš„æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼ˆä»…åœ¨ --show-think å¯ç”¨æ—¶ä½¿ç”¨ï¼Œé»˜è®¤ 8192ï¼‰')
    parser.add_argument('--shuffle', action='store_true', help='éšæœºæŠ½å– limit é“é¢˜è¿›è¡Œè¯„æµ‹/ç”Ÿæˆ')
    parser.add_argument('--wrong-out', help='å°†è¯„æµ‹ä¸­çš„é”™é¢˜è¾“å‡ºåˆ°æŒ‡å®šJSONæ–‡ä»¶ï¼ˆè¿½åŠ å†™å…¥ï¼‰')
    parser.add_argument('--mcq-file', help='æŒ‡å®šä¸€ä¸ªå«ç­”æ¡ˆçš„MCQé¢˜åº“JSONæ–‡ä»¶è¿›è¡Œè¯„æµ‹')
    args = parser.parse_args()
    
    # æ ¹æ®APIç±»å‹è°ƒæ•´é»˜è®¤base_url
    if args.api_type == 'vllm' and args.base_url == 'http://localhost:11434':
        args.base_url = 'http://localhost:8000'
    

    def run_mcq(file_path, report_prefix):
        try:
            questions, invalids = analyze_questions_file(file_path)
        except Exception as e:
            print(f"âŒ åŠ è½½é¢˜åº“å¤±è´¥: {e}")
            return {'name': report_prefix, 'total': 0, 'correct': 0}
        total_all = len(questions)
        if invalids:
            try:
                invalid_name = f"invalid_{report_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                with open(os.path.join(os.path.dirname(__file__), invalid_name), 'w', encoding='utf-8') as f:
                    json.dump(invalids, f, ensure_ascii=False, indent=2)
                print(f"âš ï¸  å·²è¿‡æ»¤ {len(invalids)} æ¡æ— æ•ˆé¢˜ç›®ï¼Œè¯¦æƒ…è§ {invalid_name}")
            except Exception as e:
                print(f"âš ï¸  æ— æ•ˆé¢˜ç›®æ˜ç»†ä¿å­˜å¤±è´¥: {e}")
        start = max(args.start, 0)
        if args.limit and args.limit > 0:
            if args.shuffle:
                k = min(args.limit, len(questions))
                questions = random.sample(questions, k)
            else:
                questions = questions[start: start + args.limit]
        else:
            questions = questions[start:]
        total = len(questions)
        if total == 0:
            print("âš ï¸  æ²¡æœ‰å¯è¯„ä¼°çš„é¢˜ç›®ã€‚")
            return {'name': report_prefix, 'total': 0, 'correct': 0}
        print(f"ğŸš€ å¼€å§‹è¯„ä¼° {report_prefix}ï¼Œå…± {total} / {total_all} é¢˜ã€‚APIç±»å‹ï¼š{args.api_type}  æ¨¡å‹ï¼š{args.model}  æœåŠ¡ï¼š{args.base_url}  çº¿ç¨‹æ•°ï¼š{args.threads}")
        progress_manager = ThreadSafeProgress(total)
        start_ms = time.time() * 1000
        try:
            question_data = [(idx, q) for idx, q in enumerate(questions, start=1)]
            with ThreadPoolExecutor(max_workers=args.threads) as executor:
                future_to_question = {executor.submit(process_single_question, qd, args, progress_manager): qd for qd in question_data}
                for future in as_completed(future_to_question):
                    try:
                        _ = future.result()
                    except Exception as e:
                        print(f"\nâŒ å¤„ç†é¢˜ç›®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­è¯„ä¼°ï¼æ­£åœ¨ç”Ÿæˆéƒ¨åˆ†ç»“æœæŠ¥å‘Š...")
        end_ms = time.time() * 1000
        completed_count, correct, results = progress_manager.get_stats()
        wrong_items = []
        try:
            for item in results:
                if not item.get('is_correct'):
                    wrong_items.append({
                        'dataset': report_prefix,
                        'id': item.get('id'),
                        'question': item.get('question'),
                        'options': item.get('options'),
                        'answer': item.get('answer'),
                        'model_answer': item.get('model_choice'),
                        'model_answer_text': item.get('model_choice_text'),
                    })
        except Exception:
            pass
        try:
            out_name = f"report_{report_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            output_path = os.path.join(os.path.dirname(__file__), out_name)
            generate_html_report(results, output_path, args.model, total_ms=end_ms - start_ms, only_errors=False, hide_question=True, summary_only=True)
            print(f"ğŸ“‹ æ¦‚è§ˆæŠ¥å‘Šå·²ç”Ÿæˆ: {out_name}")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆ HTML æŠ¥å‘Šå¤±è´¥: {e}")
        if args.wrong_out and wrong_items:
            try:
                out_path = args.wrong_out
                if not os.path.isabs(out_path):
                    out_path = os.path.join(os.path.dirname(__file__), out_path)
                existing = []
                if os.path.exists(out_path):
                    with open(out_path, 'r', encoding='utf-8') as f:
                        try:
                            existing = json.load(f)
                            if not isinstance(existing, list):
                                existing = []
                        except Exception:
                            existing = []
                with open(out_path, 'w', encoding='utf-8') as f:
                    json.dump(existing + wrong_items, f, ensure_ascii=False, indent=2)
                print(f"ğŸ“ é”™é¢˜å·²è¿½åŠ ä¿å­˜åˆ°: {os.path.basename(out_path)}  æ–°å¢: {len(wrong_items)} æ¡")
            except Exception as e:
                print(f"âš ï¸  é”™é¢˜è¾“å‡ºå¤±è´¥: {e}")
        return {'name': report_prefix, 'total': completed_count, 'correct': correct}

    def run_freeform(file_path, answers_prefix):
        try:
            questions = load_questions_freeform(file_path)
        except Exception as e:
            print(f"âŒ åŠ è½½é¢˜åº“å¤±è´¥: {e}")
            return
        total_all = len(questions)
        start = max(args.start, 0)
        if args.limit and args.limit > 0:
            if args.shuffle:
                k = min(args.limit, len(questions))
                questions = random.sample(questions, k)
            else:
                questions = questions[start: start + args.limit]
        else:
            questions = questions[start:]
        total = len(questions)
        if total == 0:
            print("âš ï¸  æ²¡æœ‰å¯è¯„ä¼°çš„é¢˜ç›®ã€‚")
            return
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {answers_prefix} ç­”æ¡ˆï¼Œé¢˜ç›®æ•° {total} / {total_all}ã€‚APIç±»å‹ï¼š{args.api_type}  æ¨¡å‹ï¼š{args.model}  æœåŠ¡ï¼š{args.base_url}  çº¿ç¨‹æ•°ï¼š{args.threads}")
        start_ms = time.time() * 1000
        results = []
        diags = []
        done_count = 0
        try:
            question_data = [(idx, q) for idx, q in enumerate(questions, start=1)]
            with ThreadPoolExecutor(max_workers=args.threads) as executor:
                futures = {executor.submit(process_single_question_freeform, qd, args): qd for qd in question_data}
                print_progress(0, total, 0)
                for future in as_completed(futures):
                    try:
                        res = future.result()
                        results.append({'question_id': res['question_id'], 'answer': res['answer']})
                        done_count += 1
                        if not res['answer']:
                            t = (res['raw'] or '')
                            qd = future_to_question = None
                            diags.append({
                                'question_id': res['question_id'],
                                'raw_len': len(t),
                                'raw_preview': t[:200],
                                'reason': 'empty_response' if not t else 'no_pattern_match'
                            })
                        print_progress(done_count, total, 0)
                    except Exception as e:
                        print(f"\nâŒ ç”Ÿæˆç­”æ¡ˆæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ç”Ÿæˆï¼")
        end_ms = time.time() * 1000
        out_name = f"answers_{answers_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            with open(os.path.join(os.path.dirname(__file__), out_name), 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“‹ ç­”æ¡ˆJSONå·²ç”Ÿæˆ: {out_name}  ç”¨æ—¶: {(end_ms - start_ms)/1000:.1f}ç§’")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç­”æ¡ˆJSONå¤±è´¥: {e}")
        if diags:
            diag_name = f"answers_{answers_prefix}_diagnostics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            try:
                with open(os.path.join(os.path.dirname(__file__), diag_name), 'w', encoding='utf-8') as f:
                    json.dump({'empty_count': len(diags), 'items': diags}, f, ensure_ascii=False, indent=2)
                print(f"âš ï¸  è¯Šæ–­æ–‡ä»¶å·²ç”Ÿæˆ: {diag_name}  ç©ºç­”æ¡ˆ: {len(diags)}")
            except Exception as e:
                print(f"âš ï¸  è¯Šæ–­æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")

    data_dir = os.path.join(os.path.dirname(__file__), 'data')
    if args.mcq_file:
        run_mcq(os.path.join(os.path.dirname(__file__), args.mcq_file) if not os.path.isabs(args.mcq_file) else args.mcq_file, 'custom')
    else:
        if args.dataset == 'strike':
            run_mcq(os.path.join(data_dir, 'StrikeEval.json'), 'StrikeEval')
        elif args.dataset == 'cissp':
            run_mcq(os.path.join(data_dir, 'cissp.json'), 'cissp')
        elif args.dataset == 'cs_eval':
            run_freeform(os.path.join(data_dir, 'cs-eval.json'), 'cs_eval')
        else:
            overall_start = time.time() * 1000
            s_summary = run_mcq(os.path.join(data_dir, 'StrikeEval.json'), 'StrikeEval')
            c_summary = run_mcq(os.path.join(data_dir, 'cissp.json'), 'cissp')
            run_freeform(os.path.join(data_dir, 'cs-eval.json'), 'cs_eval')
            overall_end = time.time() * 1000
            try:
                combined_name = f"report_overview_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
                combined_path = os.path.join(os.path.dirname(__file__), combined_name)
                generate_combined_summary([s_summary, c_summary], combined_path, args.model, total_ms=overall_end - overall_start)
                print(f"ğŸ“‹ ç»¼åˆæ¦‚è§ˆæŠ¥å‘Šå·²ç”Ÿæˆ: {combined_name}")
            except Exception as e:
                print(f"âŒ ç”Ÿæˆç»¼åˆæ¦‚è§ˆå¤±è´¥: {e}")


if __name__ == '__main__':
    main()
